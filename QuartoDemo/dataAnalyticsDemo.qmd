---
title: "Data Analysis Report"
format: pdf
jupyter: python3
---

# Introduction

This section introduces the dataset and the purpose of this analysis.

## Data Overview

Load the dataset and display basic statistics and missing values.

```{python}
#| echo: false

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


# In[32]:


df = pd.read_csv(input("Location of dataset")
)


```
## First few rows of the data set

```{python}
#| echo: false

# Display the first few rows of the dataset
print(df.head())
```

## Shape of the data set
```{python}
#| echo: false

# Check the dimensions of the dataset
print(df.shape)

```

## Describtion of data set


# Get summary statistics of numerical variables
print(df.describe())
```{python}
#| echo: false

# Check the data types of variables
print(df.dtypes)
```

## Amount of missing values in the dataset
```{python}
#| echo: false

# Check for missing values
print(df.isnull().sum())
```

For futher analysis purporses all none existing Numerical data has been filled with a mean value 

## Dataset without NaN valeus 


```{python}
#| echo: false

mean_values = df.select_dtypes(include=['number']).mean()

# Then, use fillna() on the DataFrame, passing the dictionary to fill each column with its respective mean
df = df.fillna(value=mean_values)

# Define the threshold for when to drop columns instead of rows
missing_threshold = 0.25

# Iterate through each column in the DataFrame
for column in df.columns:
    missing_percentage = df[column].isnull().mean()  # Calculate the percentage of missing values

    # Check if the column is non-numeric and has more than 25% missing values
    if not pd.api.types.is_numeric_dtype(df[column]) and missing_percentage > missing_threshold:
        # Drop the column
        df.drop(column, axis=1, inplace=True)
        print(f"Removed the entire column '{column}' because more than 25% of its values were missing.")
    elif missing_percentage > 0:
        # If it's not above the threshold or it's numeric, drop rows with missing values in this column
        initial_row_count = df.shape[0]
        df = df[df[column].notna()]
        rows_dropped = initial_row_count - df.shape[0]
        print(f"Removed {rows_dropped} rows due to missing values in the '{column}' column.")

# Optionally, display the DataFrame to see the remaining data
print("Here is how the first few rows of the cleaned dataset look:")
print(df.head())
print("Summary of missing values per column after cleaning:")
print(df.isnull().sum())

# In[35]:


print(df)
```

# In[36]:
```{python}
#| echo: false

def is_plotable(series):
    """ Check if the column is suitable for plotting. """
    if series.nunique() > 20:  # Adjust the threshold as needed
        return False
    return True

# Function to determine if a column is numeric
def is_numeric(series):
    return pd.api.types.is_numeric_dtype(series)

# Function to determine if a column is categorical with a reasonable number of unique values
def is_categorical(series):
    if pd.api.types.is_categorical_dtype(series) or series.dtype == object:
        return is_plotable(series)
    return False


def plot_histograms(df, bins=10, figsize=(10, 5)):
    """
    Plot histograms for all numeric columns in the DataFrame.

    Args:
    df (DataFrame): The pandas DataFrame containing the data.
    bins (int, optional): Number of bins for the histogram. Default is 10.
    figsize (tuple, optional): Figure size, given as (width, height). Default is (10, 5).
    """
    # Identify numeric columns by checking if they can be coerced to numeric types
    numeric_columns = df.select_dtypes(include=['number']).columns

    # Create a histogram for each numeric column
    for column in numeric_columns:
        plt.figure(figsize=figsize)
        plt.hist(df[column].dropna(), bins=bins, color='skyblue', edgecolor='black')  # Drop NA values for plotting
        plt.title(f'Histogram of {column}')
        plt.xlabel(column)
        plt.ylabel('Frequency')
        plt.grid(True)
        plt.show()


# In[42]:
```

## Histograms over the data
```{python}
#| echo: false

plot_histograms(df)

# In[39]:


def is_numeric(series):
    """Check if a column is numeric."""
    return pd.api.types.is_numeric_dtype(series)

def is_categorical(series, threshold=10):
    """Check if a column is categorical. Threshold for unique counts can be adjusted."""
    return series.dtype == object and series.nunique() <= threshold

# Identify numeric and categorical columns
numeric_columns = [col for col in df.columns if is_numeric(df[col])]
categorical_columns = [col for col in df.columns if is_categorical(df[col])]
```
## Correlation matrix over features
```{python}
#| echo: false

# Generic Correlation Analysis for numeric columns
if len(numeric_columns) > 1:
    correlation_matrix = df[numeric_columns].corr()
    print("Correlation matrix:\n", correlation_matrix)

    # Optionally, display a heatmap of the correlation matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
    plt.title('Correlation Matrix')
    plt.show()

# Generic Cross-Tabulation for pairs of categorical columns
for i in range(len(categorical_columns)):
    for j in range(i + 1, len(categorical_columns)):
        cross_tab = pd.crosstab(df[categorical_columns[i]], df[categorical_columns[j]])
        print(f"Cross-tabulation between {categorical_columns[i]} and {categorical_columns[j]}:\n", cross_tab)
        print("\n")



```